from google.adk.agents import LlmAgent
from google.adk.apps.app import App
from google.adk.models.google_llm import Gemini
from google.adk.sessions import InMemorySessionService
from google.adk.runners import Runner
import os
from dotenv import load_dotenv
import asyncio

# Load environment variables
load_dotenv()

# 1. Initialize Configuration
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("GEMINI_API_KEY not found in .env file")

# Global instances
session_service = InMemorySessionService()
gemini_model = Gemini(api_key=api_key)

# -----------------------
#       HELPER CLASSES
# -----------------------

class Part:
    def __init__(self, text: str):
        self.text = text

class UserMessage:
    def __init__(self, content: str):
        self.role = "user"
        self.parts = [Part(content)]

# -----------------------
#       TOOLS
# -----------------------

def google_search(query: str) -> str:
    print(f"  >>> [Tool] Searching Google for: {query}")
    # Simulate a rich result so the model feels satisfied and stops searching
    return f"""
    [Search Result for '{query}']
    1. (2024) Autonomous drones are projected to reduce last-mile delivery costs by 40%.
    2. (2025) New FAA regulations now allow Beyond Visual Line of Sight (BVLOS) in 20 states.
    3. Major retailers announce nationwide drone fleets for instant delivery.
    4. Public concerns regarding noise and privacy are rising, leading to new zoning laws.
    5. Economic boost: 100,000 new jobs predicted in drone maintenance and remote piloting.
    """

def analyze_data(data: str) -> str:
    print("  >>> [Tool] Analyzing Data...")
    return f"""
    [Analysis Output]
    - Trend: Cost reduction is the primary driver.
    - Constraint: Regulatory hurdles (BVLOS) are clearing up.
    - Social Impact: Privacy/Noise concerns vs. Job creation.
    """

# -----------------------
#       AGENTS
# -----------------------

researcher_agent = LlmAgent(
    name="researcher_agent",
    model=gemini_model,
    tools=[google_search]
)

analyzer_agent = LlmAgent(
    name="analyzer_agent",
    model=gemini_model,
    tools=[analyze_data]
)

summarizer_agent = LlmAgent(
    name="summarizer_agent",
    model=gemini_model,
    tools=[]
)

# FIX 1: Define the App container to register all agents.
# This prevents the "Unknown agent" warnings by making them aware of each other.
app = App(
    name="research_app",
    root_agent=researcher_agent,
    agents=[researcher_agent, analyzer_agent, summarizer_agent]
)

# -----------------------
#    WORKFLOW LOGIC
# -----------------------

async def run_agent_step(agent, user_id, session_id, prompt, step_name):
    """Helper to run a single agent step and capture output robustly."""
    print(f"\n--- {step_name} ---")
    
    # Note: We pass 'app_name' to match the App definition above
    runner = Runner(
        agent=agent,
        app_name="research_app",
        session_service=session_service
    )
    
    final_output = ""
    
    # FIX 2: Use run_async loop
    async for event in runner.run_async(
        user_id=user_id,
        session_id=session_id,
        new_message=UserMessage(prompt)
    ):
        # Capture text output. We continuously update to get the latest chunk/final result.
        if hasattr(event, 'output') and event.output:
            final_output = event.output
            # Optional: print live stream chunks if you want
            # print(event.output, end="", flush=True)

    # Fallback if output is empty (sometimes models just return the tool call event)
    if not final_output:
        final_output = "[No text output generated by agent]"

    print(f"[{agent.name} Final Output]:\n{final_output}\n")
    return final_output

async def run_multi_agent_workflow(topic: str):
    print(f"\n=== Starting Workflow for Topic: {topic} ===\n")

    USER_ID = "user_01"
    SESSION_ID = "session_01"

    # Create Session
    try:
        await session_service.create_session(
            session_id=SESSION_ID, 
            user_id=USER_ID,
            app_name="research_app"
        )
    except Exception:
        pass # Session might already exist

    # --- STEP 1: RESEARCH ---
    # Prompt injection: We explicitly tell it to STOP searching and answer.
    research_prompt = (
        f"Research the topic '{topic}'. Use the google_search tool ONCE or TWICE to find info. "
        f"AFTER searching, you MUST summarize the 3 key developments in text. "
        f"Do not just search endlessly."
    )
    research_result = await run_agent_step(
        researcher_agent, USER_ID, SESSION_ID, research_prompt, "Step 1: Researcher"
    )

    # --- STEP 2: ANALYSIS ---
    analysis_prompt = (
        f"Here is some research data: \n{research_result}\n\n"
        f"Please analyze this data using the analyze_data tool. "
        f"After the tool runs, explain the patterns you found in plain text."
    )
    analysis_result = await run_agent_step(
        analyzer_agent, USER_ID, SESSION_ID, analysis_prompt, "Step 2: Analyzer"
    )

    # --- STEP 3: SUMMARY ---
    summary_prompt = (
        f"Based on this analysis:\n{analysis_result}\n\n"
        f"Write a short executive summary for the client."
    )
    summary_result = await run_agent_step(
        summarizer_agent, USER_ID, SESSION_ID, summary_prompt, "Step 3: Summarizer"
    )

    return f"""
##########################################
       WORKFLOW COMPLETE
##########################################

[RESEARCH FINDINGS]
{research_result}

[ANALYSIS]
{analysis_result}

[EXECUTIVE SUMMARY]
{summary_result}
"""

async def main():
    topic = input("Enter research topic: ").strip()
    if not topic:
        topic = "AI Agents in 2025"
        
    result = await run_multi_agent_workflow(topic)
    print(result)

if __name__ == "__main__":
    asyncio.run(main())